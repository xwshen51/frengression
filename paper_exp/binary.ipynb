{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53989f4",
   "metadata": {},
   "source": [
    "## Experiments for binary treatment effect estimation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19983602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# add the project root to sys.path\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)\n",
    "\n",
    "from data_causl.utils import *\n",
    "from data_causl.data import *\n",
    "from frengression import *\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "import CausalEGM as cegm\n",
    "# import the module\n",
    "from models import *\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4801550b",
   "metadata": {},
   "source": [
    "## Example of hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbba039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "def tune_and_eval(model_name,\n",
    "                  X_train, t_train, y_train,\n",
    "                  X_val,   t_val,   y_val,\n",
    "                  X_test,  t_test,  y_test,\n",
    "                  provided_params=None,\n",
    "                  n_trials=10):\n",
    "    \"\"\"\n",
    "    If best_params is None: runs Optuna, returns (ITE_array, best_params).\n",
    "    If best_params is given: skips Optuna, returns ITE_array only.\n",
    "    \"\"\"\n",
    "    # 1) hyperparam search\n",
    "    if provided_params is None:\n",
    "        import optuna\n",
    "        study = optuna.create_study(direction=\"minimize\",\n",
    "                                    study_name=f\"{model_name}_tune\")\n",
    "        def objective(trial):\n",
    "            # common\n",
    "            lr     = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "            wd     = trial.suggest_loguniform(\"wd\", 1e-5, 1e-2)\n",
    "            bs     = trial.suggest_categorical(\"bs\", [32, 128, 256])\n",
    "            epochs = trial.suggest_int(\"epochs\", 200, 600)\n",
    "\n",
    "            # model‚Äêspecific\n",
    "            if model_name == \"tarnet\":\n",
    "                rep1 = trial.suggest_int(\"rep1\", 20, 50 )\n",
    "                rep2 = trial.suggest_int(\"rep2\", 50, 100)\n",
    "                head = trial.suggest_int(\"head\", 50, 100)\n",
    "                drop = trial.suggest_uniform(\"drop\", 0.0, 0.001)\n",
    "                trainer = TARNetTrainer(X_train.shape[1], [rep1,rep2], [head], drop)\n",
    "\n",
    "            elif model_name == \"cfrnet\":\n",
    "                rep1   = trial.suggest_int(\"rep1\", 50, 200)\n",
    "                rep2   = trial.suggest_int(\"rep2\", 50, 200)\n",
    "                head   = trial.suggest_int(\"head\", 50, 200)\n",
    "                drop   = trial.suggest_uniform(\"drop\", 0.0, 0.001)\n",
    "                ipm_w  = trial.suggest_loguniform(\"ipm_weight\", 0.01, 10.0)\n",
    "                trainer = CFRNetTrainer(X_train.shape[1], [rep1,rep2], [head], drop, ipm_w)\n",
    "\n",
    "            elif model_name == \"cevae\":\n",
    "                ld = trial.suggest_int(\"latent_dim\", 10, 200)\n",
    "                hd = trial.suggest_int(\"hidden_dim\", 20, 400)\n",
    "                nl = trial.suggest_int(\"num_layers\", 2, 5)     # note: 2‚Üí5 to avoid pop error\n",
    "                ns = trial.suggest_categorical(\"num_samples\", [10,50,100,200])\n",
    "                trainer = CEVAETrainer(X_train.shape[1], ld, hd, nl, ns)\n",
    "\n",
    "            else:  # dragonnet\n",
    "                sh = trial.suggest_int(\"shared_hidden\", 50, 200)\n",
    "                oh = trial.suggest_int(\"outcome_hidden\", 50, 200)\n",
    "                trainer = DragonNetTrainer(X_train.shape[1], sh, oh)\n",
    "\n",
    "            return trainer.fit(\n",
    "                X_train, t_train, y_train,\n",
    "                X_val,   t_val,   y_val,\n",
    "                lr=lr, weight_decay=wd,\n",
    "                batch_size=bs, epochs=epochs\n",
    "            )\n",
    "\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        best_params = study.best_params\n",
    "        print(f\"üîç Best params for {model_name}: {best_params}\")\n",
    "    else:\n",
    "        best_params = provided_params\n",
    "    # 2) retrain on combined train+val\n",
    "    X_trn = np.vstack([X_train, X_val])\n",
    "    t_trn = np.concatenate([t_train, t_val])\n",
    "    y_trn = np.concatenate([y_train, y_val])\n",
    "\n",
    "    if model_name == \"tarnet\":\n",
    "        trainer = TARNetTrainer(\n",
    "            X_trn.shape[1],\n",
    "            [best_params['rep1'], best_params['rep2']],\n",
    "            [best_params['head']],\n",
    "            best_params['drop']\n",
    "        )\n",
    "    elif model_name == \"cfrnet\":\n",
    "        trainer = CFRNetTrainer(\n",
    "            X_trn.shape[1],\n",
    "            [best_params['rep1'], best_params['rep2']],\n",
    "            [best_params['head']],\n",
    "            best_params['drop'],\n",
    "            best_params['ipm_weight']\n",
    "        )\n",
    "    elif model_name == \"cevae\":\n",
    "        trainer = CEVAETrainer(\n",
    "            X_trn.shape[1],\n",
    "            best_params['latent_dim'],\n",
    "            best_params['hidden_dim'],\n",
    "            best_params['num_layers'],\n",
    "            best_params['num_samples']\n",
    "        )\n",
    "    else:\n",
    "        trainer = DragonNetTrainer(\n",
    "            X_trn.shape[1],\n",
    "            best_params['shared_hidden'],\n",
    "            best_params['outcome_hidden']\n",
    "        )\n",
    "\n",
    "    trainer.fit(\n",
    "        X_trn, t_trn, y_trn,\n",
    "        X_test, t_test, y_test,\n",
    "        lr=best_params['lr'],\n",
    "        weight_decay=best_params['wd'],\n",
    "        batch_size=best_params['bs'],\n",
    "        epochs=best_params['epochs']\n",
    "    )\n",
    "\n",
    "    if model_name == \"cevae\":\n",
    "        ite = trainer.predict(X_test)\n",
    "    else:\n",
    "        y0p, y1p = trainer.predict(X_test)\n",
    "        ite = y1p - y0p\n",
    "\n",
    "    return (ite, best_params) if provided_params is None else ite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b1e42",
   "metadata": {},
   "source": [
    "## Fitting synthetic data generated by causl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2a3a2",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrep = 30  # Number of repetitions\n",
    "n_tr = 5000  # Training sample size\n",
    "n_val = 400\n",
    "n_te = 400  # Testing sample size\n",
    "strength_instr_values = np.arange(0,2.5,0.5)  # Varying strength of instrumental variables\n",
    "nI = 5 # Fixed number of instrumental variables\n",
    "nX = 5\n",
    "nO = 0\n",
    "nS = 0\n",
    "binary_intervention = True\n",
    "num_iters = 1000 # Fixed number of training iterations\n",
    "ate = 2\n",
    "strength_conf = 1\n",
    "strength_outcome = 0\n",
    "beta_cov = 0\n",
    "\n",
    "# Initialize tracker for strength_instr\n",
    "tracker = {strength_instr: {\"fr\": [], \"dr\": [], \"causalegm\":[], \"tarnet\":[], \"cfrnet\":[], \"cevae\":[], \"dragonnet\":[]}\n",
    "           for strength_instr in strength_instr_values}\n",
    "# tracker = {strength_instr: {\"fr\": [], \"dr\": [], \"causalegm\":[], \"dragonnet\":[]}\n",
    "#     for strength_instr in strength_instr_values}\n",
    "\n",
    "best_hps = {model: None for model in [\"tarnet\",\"cfrnet\",\"cevae\",\"dragonnet\"]}\n",
    "# best_hps = {model: None for model in [\"dragonnet\"]}\n",
    "# Begin loop over strength_instr\n",
    "for strength_instr in strength_instr_values:\n",
    "    print(f\"Running experiments for strength_instr = {strength_instr}\")\n",
    "    p = nI + nX + nO + nS  # Update the number of covariates\n",
    "    \n",
    "    for rep in tqdm(range(nrep)):\n",
    "        # Generate training and testing data\n",
    "        df_tr = generate_data_causl(n=n_tr, nI=nI, nX=nX, nO=nO, nS=nS, ate=ate, \n",
    "                                    beta_cov=beta_cov, strength_instr=strength_instr, \n",
    "                                    strength_conf=strength_conf, \n",
    "                                    strength_outcome=strength_outcome, \n",
    "                                    binary_intervention=binary_intervention)\n",
    "        z_tr = torch.tensor(df_tr[[f\"X{i}\" for i in range(1, p + 1)]].values, dtype=torch.float32)\n",
    "        x_tr = torch.tensor(df_tr['A'].values, dtype=torch.int32).view(-1, 1) if binary_intervention else \\\n",
    "            torch.tensor(df_tr['A'].values, dtype=torch.float32).view(-1, 1)\n",
    "        y_tr = torch.tensor(df_tr['y'].values, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        z_tr_np = df_tr[[f\"X{i}\" for i in range(1, p + 1)]].values\n",
    "        x_tr_np = df_tr['A'].values\n",
    "        y_tr_np = df_tr['y'].values\n",
    "\n",
    "        df_val = generate_data_causl(n=n_val, nI=nI, nX=nX, nO=nO, nS=nS, ate=ate, \n",
    "                                    beta_cov=beta_cov, strength_instr=strength_instr, \n",
    "                                    strength_conf=strength_conf, \n",
    "                                    strength_outcome=strength_outcome, \n",
    "                                    binary_intervention=binary_intervention)\n",
    "\n",
    "\n",
    "        z_val_np = df_val[[f\"X{i}\" for i in range(1, p + 1)]].values\n",
    "        x_val_np = df_val['A'].values\n",
    "        y_val_np = df_val['y'].values\n",
    "\n",
    "        df_te = generate_data_causl(n=n_te, nI=nI, nX=nX, nO=nO, nS=nS, ate=ate, \n",
    "                                    beta_cov=beta_cov, strength_instr=strength_instr, \n",
    "                                    strength_conf=strength_conf, \n",
    "                                    strength_outcome=strength_outcome, \n",
    "                                    binary_intervention=binary_intervention)\n",
    "\n",
    "        z_te_np = df_te[[f\"X{i}\" for i in range(1, p + 1)]].values\n",
    "        x_te_np = df_te['A'].values\n",
    "        y_te_np = df_te['y'].values\n",
    "        z_te = torch.tensor(z_te_np, dtype=torch.float32)\n",
    "\n",
    "        model = Frengression(x_dim = x_tr.shape[1], y_dim = 1, z_dim =z_tr.shape[1], \n",
    "                             noise_dim=1, num_layer=3, hidden_dim=100, \n",
    "                             device=device, x_binary=binary_intervention, z_binary_dims=0)\n",
    "\n",
    "        # Train Frengression model\n",
    "        model.train_y(x=x_tr,\n",
    "                      z=z_tr, \n",
    "                      y=y_tr, \n",
    "                      num_iters=num_iters, lr=1e-4, print_every_iter=500, tol=0)\n",
    "\n",
    "        # Sample model distributions\n",
    "        P0 = model.sample_causal_margin(torch.tensor([0], dtype=torch.int32), sample_size=n_te).numpy().reshape(-1, 1)\n",
    "        P1 = model.sample_causal_margin(torch.tensor([1], dtype=torch.int32), sample_size=n_te).numpy().reshape(-1, 1)\n",
    "        ate_fr = np.mean(P1) - np.mean(P0)\n",
    "        print(ate_fr)\n",
    "\n",
    "        # DR Estimation\n",
    "        ate_dr, _ = dr_ate(x_tr_np, y_tr_np, z_tr_np ,x_te_np, y_te_np, z_te_np)\n",
    "\n",
    "        # for model in [\"tarnet\",\"cfrnet\",\"cevae\",\"dragonnet\"]:\n",
    "        for model in [\"dragonnet\"]:\n",
    "            if rep == 0:\n",
    "                ite, best_hps[model] = tune_and_eval(\n",
    "                    model,\n",
    "                    z_tr_np, x_tr_np, y_tr_np,\n",
    "                    z_val_np, x_val_np, y_val_np,\n",
    "                    z_te_np, x_te_np,y_te_np,\n",
    "                    provided_params=None,\n",
    "                    n_trials=30\n",
    "                )\n",
    "            else:\n",
    "                ite = tune_and_eval(\n",
    "                    model,\n",
    "                    z_tr_np, x_tr_np, y_tr_np,\n",
    "                    z_val_np, x_val_np, y_val_np,\n",
    "                    z_te_np, x_te_np,y_te_np,\n",
    "                    provided_params=best_hps[model]\n",
    "                )\n",
    "            tracker[strength_instr][model].append(ite.mean())\n",
    "\n",
    "\n",
    "        cegm_params = {'dataset': 'Semi_acic', \n",
    "                        'output_dir': '.', \n",
    "                        'v_dim': z_tr.shape[1], \n",
    "                        'z_dims': [1, 1, 1, 1], \n",
    "                        'lr': 0.0002, \n",
    "                        'alpha': 1, \n",
    "                        'beta': 1, \n",
    "                        'gamma': 10, \n",
    "                        'g_d_freq': 5, \n",
    "                        'g_units': [64, 64, 64, 64, 64], \n",
    "                        'e_units': [64, 64, 64, 64, 64], \n",
    "                        'f_units': [64, 32, 8], \n",
    "                        'h_units': [64, 32, 8], \n",
    "                        'dz_units': [64, 32, 8], \n",
    "                        'dv_units': [64, 32, 8], 'save_res': False, 'save_model': False, 'binary_treatment': True, 'use_z_rec': True, 'use_v_gan': True}\n",
    "        egm_model = cegm.CausalEGM(params=cegm_params, random_seed=42)\n",
    "        egm_model.train(data=[x_tr,y_tr,z_tr],n_iter=1000, verbose=False)\n",
    "        ate_causalegm=egm_model.getCATE(z_te).mean()\n",
    "\n",
    "        # Log results\n",
    "        tracker[strength_instr][\"fr\"].append(ate_fr)\n",
    "        tracker[strength_instr][\"dr\"].append(ate_dr)\n",
    "        tracker[strength_instr][\"causalegm\"].append(ate_causalegm)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_dir = \"result/binary/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "tracker_serializable = {\n",
    "    str(k): [float(x) for x in v_dict.get(\"fr\",[])] \n",
    "              + []  # (we'll overwrite below) \n",
    "    for k, v_dict in tracker.items()\n",
    "}\n",
    "# actually build full dict:\n",
    "tracker_serializable = {\n",
    "    str(k): {\n",
    "        model: [float(x) for x in v_list]\n",
    "        for model, v_list in v_dict.items()\n",
    "    }\n",
    "    for k, v_dict in tracker.items()\n",
    "}\n",
    "\n",
    "# 3) write it out\n",
    "with open(os.path.join(output_dir, \"synthetic_1k_v2.json\"), \"w\") as f:\n",
    "    json.dump(tracker_serializable, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"result/binary/synthetic_1k_v2.json\") as f:\n",
    "    tracker = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Load your tracker\n",
    "with open(\"result/binary/synthetic_1k_v2.json\") as f:\n",
    "    tracker = json.load(f)\n",
    "\n",
    "# 2) Define strengths and methods in the order you want\n",
    "strengths = sorted(tracker.keys(), key=lambda x: float(x))\n",
    "methods   = [\"fr\",\"dr\",\"causalegm\",\"dragonnet\"]\n",
    "\n",
    "# 3) Build a MultiIndex DataFrame\n",
    "rows = []\n",
    "index = []\n",
    "for s in strengths:\n",
    "    ests = tracker[s]\n",
    "    # precompute each method‚Äôs metrics\n",
    "    stats = {}\n",
    "    for m in methods:\n",
    "        arr = np.array(ests[m])\n",
    "        stats[m] = {\n",
    "            \"rmse\": np.sqrt(((arr - 2.0)**2).mean()),\n",
    "            \"bias\": arr.mean() - 2.0,\n",
    "            \"mae\":  np.abs(arr - 2.0).mean()\n",
    "        }\n",
    "    # for each metric, make one row\n",
    "    for metric in [\"rmse\",\"bias\",\"mae\"]:\n",
    "        index.append((s, metric))\n",
    "        rows.append([stats[m][metric] for m in methods])\n",
    "\n",
    "df = pd.DataFrame(rows,\n",
    "                  index=pd.MultiIndex.from_tuples(index,\n",
    "                                                  names=[\"strength\",\"metric\"]),\n",
    "                  columns=methods)\n",
    "\n",
    "# 4) Formatting function\n",
    "def fmt(x):\n",
    "    if 1e-2 <= abs(x) < 1e0:\n",
    "        return f\"{x:.3f}\"\n",
    "    else:\n",
    "        return f\"{x:.3e}\"\n",
    "\n",
    "df_fmt = df.applymap(fmt)\n",
    "\n",
    "# 5) Print LaTeX\n",
    "print(df_fmt.to_latex(multicolumn=True, multirow=True, escape=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16307579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Load results\n",
    "with open(\"result/binary/synthetic_1k_v2.json\") as f:\n",
    "    tracker = json.load(f)\n",
    "\n",
    "# Sort strengths and define methods + swapped pastel colors + display names\n",
    "strengths = sorted(tracker.keys(), key=lambda x: float(x))\n",
    "methods   = [\"fr\", \"dr\", \"causalegm\", \"dragonnet\"]\n",
    "display_names = {\"fr\": \"Fr\", \"dr\": \"DR\", \"causalegm\": \"CausalEGM\", \"dragonnet\": \"Dragonnet\"}\n",
    "colors    = {\n",
    "    \"fr\":        \"#E15759\",  # now DR‚Äôs old pastel red\n",
    "    \"dr\":        \"#4C72B0\",  # now FR‚Äôs old pastel blue\n",
    "    \"causalegm\": \"#76B7B2\",  # pastel teal\n",
    "    \"dragonnet\": \"#B07AA1\",  # pastel purple\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "n = len(strengths)\n",
    "m = len(methods)\n",
    "total_width = .6\n",
    "box_width = total_width / m * 1.2\n",
    "\n",
    "# Plot bias boxplots\n",
    "for i, s in enumerate(strengths):\n",
    "    for j, meth in enumerate(methods):\n",
    "        offset = (j - (m - 1) / 2) * (total_width / m)\n",
    "        pos = i + offset\n",
    "        bias = np.array(tracker[s][meth]) - 2.0\n",
    "        ax.boxplot(\n",
    "            bias,\n",
    "            positions=[pos],\n",
    "            widths=box_width,\n",
    "            patch_artist=True,\n",
    "            boxprops=dict(facecolor=colors[meth], alpha=0.9, edgecolor='gray'),\n",
    "            whiskerprops=dict(color='gray'),\n",
    "            capprops=dict(color='gray'),\n",
    "            medianprops=dict(color='black', linewidth=1)\n",
    "        )\n",
    "\n",
    "# Zero‚Äêbias line (no legend entry)\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "# Clean up axes\n",
    "ax.set_xticks(range(n))\n",
    "ax.set_xticklabels(strengths)\n",
    "ax.set_xlabel(\"Instrumental Variable Strength\")\n",
    "ax.set_ylabel(\"Bias (Estimate ‚Äì True ATE)\")\n",
    "ax.grid(False)\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Legend: only the four methods\n",
    "handles = [Patch(facecolor=colors[m], label=display_names[m]) for m in methods]\n",
    "ax.legend(handles=handles, loc=\"upper right\", frameon=False)\n",
    "\n",
    "ax.set_title(\"Bias  across Instrumental Variable Strengths\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a96248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load results\n",
    "with open(\"result/binary/synthetic_1k_v2.json\") as f:\n",
    "    tracker = json.load(f)\n",
    "\n",
    "# Sort strengths and define methods + updated colors + display names\n",
    "strengths = sorted(tracker.keys(), key=lambda x: float(x))\n",
    "methods   = [\"fr\", \"dr\", \"causalegm\", \"dragonnet\"]\n",
    "display_names = {\"fr\": \"Fr\", \"dr\": \"DR\", \"causalegm\": \"CausalEGM\", \"dragonnet\": \"Dragonnet\"}\n",
    "colors    = {\n",
    "    \"fr\":        \"#E15759\",  # swapped pastel red\n",
    "    \"dr\":        \"#4C72B0\",  # swapped pastel blue\n",
    "    \"causalegm\": \"#76B7B2\",  # pastel teal\n",
    "    \"dragonnet\": \"#B07AA1\",  # pastel purple (new)\n",
    "}\n",
    "\n",
    "# Prepare figure\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(strengths))\n",
    "\n",
    "# Plot each method's mean ¬± IQR\n",
    "for meth in methods:\n",
    "    all_bias = [np.array(tracker[s][meth]) - 2.0 for s in strengths]\n",
    "    means = np.array([b.mean() for b in all_bias])\n",
    "    q1    = np.array([np.percentile(b, 1) for b in all_bias])\n",
    "    q3    = np.array([np.percentile(b, 99) for b in all_bias])\n",
    "    \n",
    "    ax.plot(x, means, label=display_names[meth],\n",
    "            color=colors[meth], marker='o', linewidth=2)\n",
    "    ax.fill_between(x, q1, q3, color=colors[meth], alpha=0.2)\n",
    "\n",
    "# Zero bias line\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "# Axes & labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(strengths)\n",
    "ax.set_xlabel(\"Instrument Strength\")\n",
    "ax.set_ylabel(\"Bias (Estimate ‚Äì True ATE)\")\n",
    "ax.set_facecolor('white')\n",
    "ax.grid(False)\n",
    "\n",
    "# Legend only the methods\n",
    "ax.legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "ax.set_title(\"Mean Bias ¬± IQR of ATE Estimators across Instrument Strengths\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
