{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53989f4",
   "metadata": {},
   "source": [
    "## Experiments for binary treatment effect estimation comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19983602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# add the project root to sys.path\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)\n",
    "\n",
    "from data_causl.utils import *\n",
    "from data_causl.data import *\n",
    "from frengression import *\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "from CausalEGM import *\n",
    "# import the module\n",
    "from dragonnet.dragonnet import DragonNet # https://github.com/farazmah/dragonnet-pytorch\n",
    "from catenets.models.torch import TARNet\n",
    "from pyro.contrib.cevae import CEVAE\n",
    "\n",
    "# X: [NÃ—D], t: [N], y: [N]\n",
    "cevae = CEVAE(feature_dim=D)\n",
    "cevae.fit(torch.tensor(X), torch.tensor(t), torch.tensor(y))\n",
    "ite = cevae.ite(torch.tensor(X_test))  # returns per-sample effects\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(2024)\n",
    "n_tr = 1000\n",
    "n_p = 1000\n",
    "\n",
    "nI = 2\n",
    "nX = 2\n",
    "nO = 2\n",
    "nS= 2\n",
    "p = nI+nX+nO+nS\n",
    "ate = 2\n",
    "beta_cov = 0\n",
    "strength_instr = 1\n",
    "strength_conf = 1\n",
    "strength_outcome = 1\n",
    "binary_intervention=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bd365ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 20:38:19,755] A new study created in memory with name: tarnet_tune\n",
      "[I 2025-04-24 20:38:19,932] Trial 0 finished with value: 0.040450528264045715 and parameters: {'lr': 0.0004994689501493047, 'wd': 4.886282511483952e-05, 'bs': 64, 'epochs': 48, 'rep1': 100, 'rep2': 100, 'head': 150, 'drop': 0.42985230220261156}. Best is trial 0 with value: 0.040450528264045715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning and training TARNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 20:38:20,121] Trial 1 finished with value: 0.022942176088690758 and parameters: {'lr': 0.007955498151842575, 'wd': 0.00011449883718167686, 'bs': 64, 'epochs': 53, 'rep1': 100, 'rep2': 200, 'head': 50, 'drop': 0.03220843654610184}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,312] Trial 2 finished with value: 0.02519337460398674 and parameters: {'lr': 0.0020630840624249716, 'wd': 0.0003783508656240764, 'bs': 64, 'epochs': 53, 'rep1': 200, 'rep2': 100, 'head': 100, 'drop': 0.20117938788096745}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,425] Trial 3 finished with value: 0.03102118894457817 and parameters: {'lr': 0.00047758478415335106, 'wd': 0.00021975273678424403, 'bs': 128, 'epochs': 43, 'rep1': 100, 'rep2': 100, 'head': 150, 'drop': 0.1347563316704551}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,572] Trial 4 finished with value: 0.041703782975673676 and parameters: {'lr': 0.0047927428101625785, 'wd': 2.91266013774836e-05, 'bs': 128, 'epochs': 47, 'rep1': 200, 'rep2': 200, 'head': 100, 'drop': 0.47727083486324523}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,623] Trial 5 finished with value: 0.028717482462525368 and parameters: {'lr': 0.0056894059926165235, 'wd': 3.225511554827045e-06, 'bs': 128, 'epochs': 20, 'rep1': 200, 'rep2': 100, 'head': 50, 'drop': 0.32240970312733813}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,698] Trial 6 finished with value: 0.039490558207035065 and parameters: {'lr': 0.0024633602411320474, 'wd': 0.0006520340303589086, 'bs': 256, 'epochs': 30, 'rep1': 200, 'rep2': 200, 'head': 100, 'drop': 0.387020611041756}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,808] Trial 7 finished with value: 0.030219007283449173 and parameters: {'lr': 0.0007539261589551683, 'wd': 0.00013305403545909434, 'bs': 128, 'epochs': 45, 'rep1': 200, 'rep2': 100, 'head': 50, 'drop': 0.24362873394365947}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,854] Trial 8 finished with value: 0.44535842537879944 and parameters: {'lr': 0.00043951349973384674, 'wd': 1.4033714638210646e-05, 'bs': 256, 'epochs': 21, 'rep1': 200, 'rep2': 100, 'head': 100, 'drop': 0.15980473050115024}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:20,923] Trial 9 finished with value: 0.039034754037857056 and parameters: {'lr': 0.0013706333303516254, 'wd': 9.502079502773579e-05, 'bs': 128, 'epochs': 30, 'rep1': 100, 'rep2': 100, 'head': 50, 'drop': 0.2550239005833932}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:21,142] Trial 10 finished with value: 0.03432717174291611 and parameters: {'lr': 0.00011551386509253723, 'wd': 1.0298013956968504e-06, 'bs': 64, 'epochs': 60, 'rep1': 100, 'rep2': 200, 'head': 50, 'drop': 0.00805180615252499}. Best is trial 1 with value: 0.022942176088690758.\n",
      "[I 2025-04-24 20:38:21,366] Trial 11 finished with value: 0.019590038806200027 and parameters: {'lr': 0.0026056732869375473, 'wd': 0.0007496160991952458, 'bs': 64, 'epochs': 57, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.0037622709223809614}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:21,616] Trial 12 finished with value: 0.02025684155523777 and parameters: {'lr': 0.007630609536683363, 'wd': 0.0009395594050139386, 'bs': 64, 'epochs': 60, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.018384686179845625}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:21,862] Trial 13 finished with value: 0.024343283846974373 and parameters: {'lr': 0.009938823147959077, 'wd': 0.000985295211034322, 'bs': 64, 'epochs': 59, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.09237156784457695}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:22,082] Trial 14 finished with value: 0.022260334342718124 and parameters: {'lr': 0.003381254406089482, 'wd': 0.0004285600302732267, 'bs': 64, 'epochs': 52, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.08873528131037806}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:22,232] Trial 15 finished with value: 0.020623886957764626 and parameters: {'lr': 0.00380554006207684, 'wd': 0.000998423072002211, 'bs': 64, 'epochs': 38, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.001172875807251346}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:22,474] Trial 16 finished with value: 0.02058984711766243 and parameters: {'lr': 0.0014728246631735018, 'wd': 8.740516011365955e-06, 'bs': 64, 'epochs': 57, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.07824137717182356}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:22,563] Trial 17 finished with value: 0.025154298171401024 and parameters: {'lr': 0.006120644927694591, 'wd': 0.0002826260108217711, 'bs': 256, 'epochs': 38, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.05427998456729846}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:22,774] Trial 18 finished with value: 0.025954246520996094 and parameters: {'lr': 0.00019804792143144546, 'wd': 5.395910767765973e-05, 'bs': 64, 'epochs': 55, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.13636764461424017}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:22,983] Trial 19 finished with value: 0.028351087123155594 and parameters: {'lr': 0.002718832918010926, 'wd': 0.00018771134922253855, 'bs': 64, 'epochs': 50, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.3118900683576962}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:23,064] Trial 20 finished with value: 0.05708951875567436 and parameters: {'lr': 0.0011015771239126005, 'wd': 0.0005189433908345463, 'bs': 256, 'epochs': 33, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.1891398281859592}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:23,327] Trial 21 finished with value: 0.021793795749545097 and parameters: {'lr': 0.001899941731319886, 'wd': 6.7877839436425875e-06, 'bs': 64, 'epochs': 57, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.06990027631905169}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:23,575] Trial 22 finished with value: 0.021700197830796242 and parameters: {'lr': 0.0015235116574606098, 'wd': 1.112982948954948e-05, 'bs': 64, 'epochs': 60, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.10382709603298299}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:23,808] Trial 23 finished with value: 0.019714204594492912 and parameters: {'lr': 0.0007489887026222087, 'wd': 4.293269030886101e-06, 'bs': 64, 'epochs': 56, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.04307595008188885}. Best is trial 11 with value: 0.019590038806200027.\n",
      "[I 2025-04-24 20:38:24,044] Trial 24 finished with value: 0.01913325861096382 and parameters: {'lr': 0.0006487383734562559, 'wd': 1.6709604240203095e-06, 'bs': 64, 'epochs': 56, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.03826401833393277}. Best is trial 24 with value: 0.01913325861096382.\n",
      "[I 2025-04-24 20:38:24,279] Trial 25 finished with value: 0.02055760659277439 and parameters: {'lr': 0.00028005849026210773, 'wd': 1.0328288164241547e-06, 'bs': 64, 'epochs': 56, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.03648327535716859}. Best is trial 24 with value: 0.01913325861096382.\n",
      "[I 2025-04-24 20:38:24,480] Trial 26 finished with value: 0.021307554095983505 and parameters: {'lr': 0.0008023777232214835, 'wd': 2.789697689762401e-06, 'bs': 64, 'epochs': 50, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.12223890070987377}. Best is trial 24 with value: 0.01913325861096382.\n",
      "[I 2025-04-24 20:38:24,663] Trial 27 finished with value: 0.017989134415984154 and parameters: {'lr': 0.0006750814407541536, 'wd': 2.288879600687233e-06, 'bs': 64, 'epochs': 43, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 3.431328529691219e-05}. Best is trial 27 with value: 0.017989134415984154.\n",
      "[I 2025-04-24 20:38:24,761] Trial 28 finished with value: 0.08010594546794891 and parameters: {'lr': 0.0003311481152591815, 'wd': 1.8515979959414443e-06, 'bs': 256, 'epochs': 42, 'rep1': 100, 'rep2': 200, 'head': 100, 'drop': 0.0025345129175775496}. Best is trial 27 with value: 0.017989134415984154.\n",
      "[I 2025-04-24 20:38:24,965] Trial 29 finished with value: 0.02007255330681801 and parameters: {'lr': 0.0005583539463713288, 'wd': 2.203102324234154e-05, 'bs': 64, 'epochs': 47, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 0.05823700436993481}. Best is trial 27 with value: 0.017989134415984154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for tarnet: {'lr': 0.0006750814407541536, 'wd': 2.288879600687233e-06, 'bs': 64, 'epochs': 43, 'rep1': 100, 'rep2': 200, 'head': 150, 'drop': 3.431328529691219e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 20:38:25,187] A new study created in memory with name: cevae_tune\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:25,336] Trial 0 finished with value: 13.590973663330079 and parameters: {'lr': 0.0002680757208310392, 'wd': 7.53440203370384e-06, 'bs': 256, 'epochs': 30, 'latent_dim': 25, 'hidden_dim': 188, 'num_layers': 2, 'num_samples': 10}. Best is trial 0 with value: 13.590973663330079.\n",
      "INFO \t Training with 4 minibatches per epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARNet ITE shape: (80,)\n",
      "Tuning and training CEVAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 20:38:25,870] Trial 1 finished with value: 10.820096397399903 and parameters: {'lr': 0.0004513322364411776, 'wd': 2.4012210537286576e-05, 'bs': 64, 'epochs': 35, 'latent_dim': 13, 'hidden_dim': 105, 'num_layers': 4, 'num_samples': 10}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:26,387] Trial 2 finished with value: 11.075271479288737 and parameters: {'lr': 0.0023287815570887972, 'wd': 5.022581646361076e-06, 'bs': 64, 'epochs': 36, 'latent_dim': 34, 'hidden_dim': 58, 'num_layers': 4, 'num_samples': 10}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:26,743] Trial 3 finished with value: 17.482425181070962 and parameters: {'lr': 0.00017177227711979916, 'wd': 0.0005270547830928239, 'bs': 128, 'epochs': 36, 'latent_dim': 79, 'hidden_dim': 94, 'num_layers': 4, 'num_samples': 100}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:26,967] Trial 4 finished with value: 11.422996266682942 and parameters: {'lr': 0.00046567862679422803, 'wd': 6.136137119177508e-05, 'bs': 128, 'epochs': 30, 'latent_dim': 12, 'hidden_dim': 193, 'num_layers': 2, 'num_samples': 100}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:27,449] Trial 5 finished with value: 20.31343625386556 and parameters: {'lr': 0.003682296681025638, 'wd': 1.3669652033210023e-06, 'bs': 64, 'epochs': 32, 'latent_dim': 84, 'hidden_dim': 131, 'num_layers': 3, 'num_samples': 100}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:27,761] Trial 6 finished with value: 10.827615610758464 and parameters: {'lr': 0.00015047690123876946, 'wd': 0.0005051242739860768, 'bs': 256, 'epochs': 59, 'latent_dim': 13, 'hidden_dim': 166, 'num_layers': 3, 'num_samples': 10}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:27,998] Trial 7 finished with value: 18.78171469370524 and parameters: {'lr': 0.0006042595166850335, 'wd': 0.0003518400966828166, 'bs': 256, 'epochs': 32, 'latent_dim': 84, 'hidden_dim': 175, 'num_layers': 4, 'num_samples': 10}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:28,616] Trial 8 finished with value: 12.097380383809407 and parameters: {'lr': 0.0015226138773950864, 'wd': 4.10555678561061e-06, 'bs': 64, 'epochs': 49, 'latent_dim': 33, 'hidden_dim': 65, 'num_layers': 3, 'num_samples': 10}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:28,820] Trial 9 finished with value: 14.538654772440593 and parameters: {'lr': 0.005867653583657148, 'wd': 2.398772364712423e-05, 'bs': 128, 'epochs': 22, 'latent_dim': 40, 'hidden_dim': 77, 'num_layers': 3, 'num_samples': 100}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:29,533] Trial 10 finished with value: 15.343360328674317 and parameters: {'lr': 0.000979416436988679, 'wd': 6.488288366030497e-05, 'bs': 64, 'epochs': 45, 'latent_dim': 55, 'hidden_dim': 119, 'num_layers': 4, 'num_samples': 50}. Best is trial 1 with value: 10.820096397399903.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:29,852] Trial 11 finished with value: 10.64513988494873 and parameters: {'lr': 0.00012656059632749068, 'wd': 0.00015742444919473412, 'bs': 256, 'epochs': 57, 'latent_dim': 14, 'hidden_dim': 151, 'num_layers': 3, 'num_samples': 10}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:30,145] Trial 12 finished with value: 20.78763338724772 and parameters: {'lr': 0.00010106790322408225, 'wd': 0.00011388302388871351, 'bs': 256, 'epochs': 60, 'latent_dim': 54, 'hidden_dim': 144, 'num_layers': 2, 'num_samples': 50}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:30,425] Trial 13 finished with value: 11.758371035257975 and parameters: {'lr': 0.0003455789522850645, 'wd': 1.9669128235565678e-05, 'bs': 256, 'epochs': 52, 'latent_dim': 18, 'hidden_dim': 108, 'num_layers': 3, 'num_samples': 10}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:31,155] Trial 14 finished with value: 15.271352322896321 and parameters: {'lr': 0.0007888275256310142, 'wd': 0.00019232188246761433, 'bs': 64, 'epochs': 43, 'latent_dim': 45, 'hidden_dim': 145, 'num_layers': 4, 'num_samples': 10}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:31,289] Trial 15 finished with value: 21.66912619272868 and parameters: {'lr': 0.0002378092715192007, 'wd': 0.0009683954514132499, 'bs': 256, 'epochs': 21, 'latent_dim': 99, 'hidden_dim': 94, 'num_layers': 3, 'num_samples': 10}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:32,191] Trial 16 finished with value: 12.33470884958903 and parameters: {'lr': 0.00012365042819982046, 'wd': 1.5044812103040902e-05, 'bs': 64, 'epochs': 53, 'latent_dim': 26, 'hidden_dim': 157, 'num_layers': 4, 'num_samples': 50}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 4 minibatches per epoch\n",
      "[I 2025-04-24 20:38:32,704] Trial 17 finished with value: 21.118318303426108 and parameters: {'lr': 0.009646192253221504, 'wd': 4.222961325572959e-05, 'bs': 64, 'epochs': 42, 'latent_dim': 65, 'hidden_dim': 126, 'num_layers': 2, 'num_samples': 10}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 1 minibatches per epoch\n",
      "[I 2025-04-24 20:38:32,843] Trial 18 finished with value: 12.266102727254232 and parameters: {'lr': 0.00048018512073020513, 'wd': 0.0001498185111980446, 'bs': 256, 'epochs': 25, 'latent_dim': 23, 'hidden_dim': 100, 'num_layers': 3, 'num_samples': 10}. Best is trial 11 with value: 10.64513988494873.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:33,169] Trial 19 finished with value: 9.828103828430176 and parameters: {'lr': 0.0015752838270200423, 'wd': 1.1524519408112888e-05, 'bs': 128, 'epochs': 37, 'latent_dim': 10, 'hidden_dim': 82, 'num_layers': 4, 'num_samples': 50}. Best is trial 19 with value: 9.828103828430176.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:33,560] Trial 20 finished with value: 17.098300997416178 and parameters: {'lr': 0.0015879561729156932, 'wd': 1.3042965690806063e-06, 'bs': 128, 'epochs': 48, 'latent_dim': 67, 'hidden_dim': 73, 'num_layers': 3, 'num_samples': 50}. Best is trial 19 with value: 9.828103828430176.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:33,890] Trial 21 finished with value: 10.222923851013183 and parameters: {'lr': 0.0016202776377554652, 'wd': 1.0935877018639116e-05, 'bs': 128, 'epochs': 37, 'latent_dim': 10, 'hidden_dim': 83, 'num_layers': 4, 'num_samples': 50}. Best is trial 19 with value: 9.828103828430176.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:34,203] Trial 22 finished with value: 10.51689001719157 and parameters: {'lr': 0.001607743295707178, 'wd': 1.074449441174163e-05, 'bs': 128, 'epochs': 39, 'latent_dim': 10, 'hidden_dim': 53, 'num_layers': 4, 'num_samples': 50}. Best is trial 19 with value: 9.828103828430176.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:34,520] Trial 23 finished with value: 11.680573654174804 and parameters: {'lr': 0.0016934894817157852, 'wd': 9.47864545323706e-06, 'bs': 128, 'epochs': 39, 'latent_dim': 21, 'hidden_dim': 54, 'num_layers': 4, 'num_samples': 50}. Best is trial 19 with value: 9.828103828430176.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:34,856] Trial 24 finished with value: 9.128949038187663 and parameters: {'lr': 0.0028436412555809133, 'wd': 2.7020290041516205e-06, 'bs': 128, 'epochs': 38, 'latent_dim': 10, 'hidden_dim': 82, 'num_layers': 4, 'num_samples': 50}. Best is trial 24 with value: 9.128949038187663.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:35,106] Trial 25 finished with value: 12.296065839131673 and parameters: {'lr': 0.003020222447224099, 'wd': 2.4631027987439016e-06, 'bs': 128, 'epochs': 27, 'latent_dim': 29, 'hidden_dim': 82, 'num_layers': 4, 'num_samples': 50}. Best is trial 24 with value: 9.128949038187663.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:35,470] Trial 26 finished with value: 14.692088254292806 and parameters: {'lr': 0.004616881536346554, 'wd': 4.375955390261555e-06, 'bs': 128, 'epochs': 40, 'latent_dim': 42, 'hidden_dim': 82, 'num_layers': 4, 'num_samples': 50}. Best is trial 24 with value: 9.128949038187663.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:35,897] Trial 27 finished with value: 10.539364242553711 and parameters: {'lr': 0.002441081974237709, 'wd': 2.555150613143407e-06, 'bs': 128, 'epochs': 45, 'latent_dim': 17, 'hidden_dim': 114, 'num_layers': 4, 'num_samples': 50}. Best is trial 24 with value: 9.128949038187663.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:36,223] Trial 28 finished with value: 12.300496800740559 and parameters: {'lr': 0.001204610823038603, 'wd': 2.29992574742243e-06, 'bs': 128, 'epochs': 35, 'latent_dim': 33, 'hidden_dim': 89, 'num_layers': 4, 'num_samples': 50}. Best is trial 24 with value: 9.128949038187663.\n",
      "INFO \t Training with 2 minibatches per epoch\n",
      "[I 2025-04-24 20:38:36,477] Trial 29 finished with value: 11.503965695699057 and parameters: {'lr': 0.006519822391075792, 'wd': 7.210325633175333e-06, 'bs': 128, 'epochs': 29, 'latent_dim': 24, 'hidden_dim': 71, 'num_layers': 4, 'num_samples': 50}. Best is trial 24 with value: 9.128949038187663.\n",
      "INFO \t Training with 3 minibatches per epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for cevae: {'lr': 0.0028436412555809133, 'wd': 2.7020290041516205e-06, 'bs': 128, 'epochs': 38, 'latent_dim': 10, 'hidden_dim': 82, 'num_layers': 4, 'num_samples': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO \t Evaluating 1 minibatches\n",
      "[I 2025-04-24 20:38:36,952] A new study created in memory with name: dragonnet_tune\n",
      "[I 2025-04-24 20:38:37,145] Trial 0 finished with value: 0.02311547100543976 and parameters: {'lr': 0.009035165710312931, 'wd': 2.892278644424301e-05, 'bs': 64, 'epochs': 36, 'shared_hidden': 159, 'outcome_hidden': 196}. Best is trial 0 with value: 0.02311547100543976.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEVAE ITE shape: ()\n",
      "Tuning and training DragonNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 20:38:37,277] Trial 1 finished with value: 0.02035456709563732 and parameters: {'lr': 0.00047778814865433595, 'wd': 0.00033016151836169464, 'bs': 128, 'epochs': 45, 'shared_hidden': 123, 'outcome_hidden': 125}. Best is trial 1 with value: 0.02035456709563732.\n",
      "[I 2025-04-24 20:38:37,463] Trial 2 finished with value: 0.02062293514609337 and parameters: {'lr': 0.008227575578011268, 'wd': 8.526111829171785e-06, 'bs': 128, 'epochs': 56, 'shared_hidden': 110, 'outcome_hidden': 200}. Best is trial 1 with value: 0.02035456709563732.\n",
      "[I 2025-04-24 20:38:37,600] Trial 3 finished with value: 0.020305996760725975 and parameters: {'lr': 0.0005777826642197931, 'wd': 0.0008023549564377211, 'bs': 64, 'epochs': 39, 'shared_hidden': 80, 'outcome_hidden': 66}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:37,702] Trial 4 finished with value: 0.7565242648124695 and parameters: {'lr': 0.00022333130290256336, 'wd': 0.0008888479896610172, 'bs': 256, 'epochs': 55, 'shared_hidden': 80, 'outcome_hidden': 76}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:37,827] Trial 5 finished with value: 0.022012680768966675 and parameters: {'lr': 0.002795702665431248, 'wd': 2.481288572616408e-06, 'bs': 128, 'epochs': 51, 'shared_hidden': 76, 'outcome_hidden': 79}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:38,053] Trial 6 finished with value: 0.020862368866801262 and parameters: {'lr': 0.0014318670833324046, 'wd': 3.962595634370694e-05, 'bs': 64, 'epochs': 55, 'shared_hidden': 164, 'outcome_hidden': 58}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:38,202] Trial 7 finished with value: 0.02125786803662777 and parameters: {'lr': 0.0027415448204725443, 'wd': 4.7648245551677785e-06, 'bs': 128, 'epochs': 52, 'shared_hidden': 115, 'outcome_hidden': 113}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:38,307] Trial 8 finished with value: 0.04326549917459488 and parameters: {'lr': 0.00023640612708075904, 'wd': 2.9666469993466627e-05, 'bs': 64, 'epochs': 22, 'shared_hidden': 107, 'outcome_hidden': 189}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:38,374] Trial 9 finished with value: 0.9563295245170593 and parameters: {'lr': 0.00017806762848719248, 'wd': 1.8120021288455471e-06, 'bs': 256, 'epochs': 29, 'shared_hidden': 103, 'outcome_hidden': 147}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:38,512] Trial 10 finished with value: 0.023798421025276184 and parameters: {'lr': 0.0006541246640634892, 'wd': 0.00018162569214322672, 'bs': 64, 'epochs': 39, 'shared_hidden': 52, 'outcome_hidden': 51}. Best is trial 3 with value: 0.020305996760725975.\n",
      "[I 2025-04-24 20:38:38,649] Trial 11 finished with value: 0.020267415791749954 and parameters: {'lr': 0.0005487516577765885, 'wd': 0.0008938917762446382, 'bs': 128, 'epochs': 44, 'shared_hidden': 144, 'outcome_hidden': 116}. Best is trial 11 with value: 0.020267415791749954.\n",
      "[I 2025-04-24 20:38:38,794] Trial 12 finished with value: 0.020603591576218605 and parameters: {'lr': 0.00045648198231570486, 'wd': 0.0009528446969409728, 'bs': 128, 'epochs': 44, 'shared_hidden': 190, 'outcome_hidden': 101}. Best is trial 11 with value: 0.020267415791749954.\n",
      "[I 2025-04-24 20:38:38,951] Trial 13 finished with value: 0.020121466368436813 and parameters: {'lr': 0.0012190825359535951, 'wd': 0.00017241078658741517, 'bs': 64, 'epochs': 32, 'shared_hidden': 150, 'outcome_hidden': 152}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,033] Trial 14 finished with value: 0.05902712792158127 and parameters: {'lr': 0.0011281762302304665, 'wd': 0.00015496019684749205, 'bs': 256, 'epochs': 32, 'shared_hidden': 148, 'outcome_hidden': 155}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,124] Trial 15 finished with value: 0.024834569543600082 and parameters: {'lr': 0.0019868466914410216, 'wd': 7.583167725650383e-05, 'bs': 128, 'epochs': 25, 'shared_hidden': 143, 'outcome_hidden': 155}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,373] Trial 16 finished with value: 0.023838751018047333 and parameters: {'lr': 0.00010735484370883682, 'wd': 0.00036555259388872406, 'bs': 64, 'epochs': 46, 'shared_hidden': 185, 'outcome_hidden': 174}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,526] Trial 17 finished with value: 0.022246215492486954 and parameters: {'lr': 0.004682524730052479, 'wd': 0.00034855108908310835, 'bs': 64, 'epochs': 32, 'shared_hidden': 137, 'outcome_hidden': 135}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,641] Trial 18 finished with value: 0.022424165159463882 and parameters: {'lr': 0.0008479668049359341, 'wd': 7.939972161729492e-05, 'bs': 128, 'epochs': 35, 'shared_hidden': 174, 'outcome_hidden': 95}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,752] Trial 19 finished with value: 0.08011506497859955 and parameters: {'lr': 0.0003427693284467004, 'wd': 0.00017938770739633092, 'bs': 256, 'epochs': 42, 'shared_hidden': 135, 'outcome_hidden': 172}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:39,916] Trial 20 finished with value: 0.02049500122666359 and parameters: {'lr': 0.0015966271722716988, 'wd': 1.2078237989127568e-05, 'bs': 128, 'epochs': 49, 'shared_hidden': 158, 'outcome_hidden': 132}. Best is trial 13 with value: 0.020121466368436813.\n",
      "[I 2025-04-24 20:38:40,079] Trial 21 finished with value: 0.01785651221871376 and parameters: {'lr': 0.0007446133996675199, 'wd': 0.0005419686217158935, 'bs': 64, 'epochs': 40, 'shared_hidden': 85, 'outcome_hidden': 110}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:40,188] Trial 22 finished with value: 0.02261934243142605 and parameters: {'lr': 0.0009758974293803548, 'wd': 0.0005112005279817057, 'bs': 64, 'epochs': 27, 'shared_hidden': 52, 'outcome_hidden': 110}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:40,370] Trial 23 finished with value: 0.020508568733930588 and parameters: {'lr': 0.0007461832842565942, 'wd': 0.00011478430775272717, 'bs': 64, 'epochs': 36, 'shared_hidden': 93, 'outcome_hidden': 114}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:40,537] Trial 24 finished with value: 0.02099786326289177 and parameters: {'lr': 0.0003535572947187124, 'wd': 0.0005028187110087237, 'bs': 64, 'epochs': 40, 'shared_hidden': 128, 'outcome_hidden': 91}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:40,720] Trial 25 finished with value: 0.021142225712537766 and parameters: {'lr': 0.0011057616718411923, 'wd': 0.00024032805133427257, 'bs': 64, 'epochs': 32, 'shared_hidden': 171, 'outcome_hidden': 144}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:41,004] Trial 26 finished with value: 0.02141164243221283 and parameters: {'lr': 0.0025250036842302437, 'wd': 0.0006399844018852414, 'bs': 64, 'epochs': 60, 'shared_hidden': 153, 'outcome_hidden': 121}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:41,236] Trial 27 finished with value: 0.02037806808948517 and parameters: {'lr': 0.00038208986363010337, 'wd': 0.0002837569916128408, 'bs': 64, 'epochs': 49, 'shared_hidden': 95, 'outcome_hidden': 167}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:41,334] Trial 28 finished with value: 0.029590025544166565 and parameters: {'lr': 0.0013203249794059293, 'wd': 5.7798372007796514e-05, 'bs': 256, 'epochs': 42, 'shared_hidden': 125, 'outcome_hidden': 102}. Best is trial 21 with value: 0.01785651221871376.\n",
      "[I 2025-04-24 20:38:41,443] Trial 29 finished with value: 0.021218810230493546 and parameters: {'lr': 0.005507069796946981, 'wd': 0.0005051646929908417, 'bs': 128, 'epochs': 35, 'shared_hidden': 70, 'outcome_hidden': 136}. Best is trial 21 with value: 0.01785651221871376.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for dragonnet: {'lr': 0.0007446133996675199, 'wd': 0.0005419686217158935, 'bs': 64, 'epochs': 40, 'shared_hidden': 85, 'outcome_hidden': 110}\n",
      "DragonNet ITE shape: (80, 1)\n",
      "All models complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from pyro.contrib.cevae import CEVAE\n",
    "from dragonnet.dragonnet import DragonNet\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1) TARNetModel + Trainer\n",
    "# ------------------------------------------------------------------------\n",
    "def mmd_rbf(x, y, gamma=None):\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    y_flat = y.view(y.size(0), -1)\n",
    "    Z = torch.cat([x_flat, y_flat], dim=0)\n",
    "    dist = (\n",
    "        Z.pow(2).sum(1, keepdim=True)\n",
    "        - 2 * Z @ Z.t()\n",
    "        + Z.pow(2).sum(1, keepdim=True).t()\n",
    "    )\n",
    "    if gamma is None:\n",
    "        d = dist.detach().cpu().numpy()\n",
    "        gamma = 1.0 / (0.5 * np.median(d[d > 0]))\n",
    "    K = torch.exp(-gamma * dist)\n",
    "    n = x_flat.size(0)\n",
    "    return K[:n, :n].mean() + K[n:, n:].mean() - 2 * K[:n, n:].mean()\n",
    "\n",
    "class TARNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, rep_dims, head_dims, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in rep_dims:\n",
    "            layers += [nn.Linear(last_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            last_dim = h\n",
    "        self.repr_net = nn.Sequential(*layers)\n",
    "\n",
    "        def make_head(in_dim):\n",
    "            head_layers = []\n",
    "            cur = in_dim\n",
    "            for h in head_dims:\n",
    "                head_layers += [nn.Linear(cur, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "                cur = h\n",
    "            head_layers += [nn.Linear(cur, 1)]\n",
    "            return nn.Sequential(*head_layers)\n",
    "\n",
    "        self.h0 = make_head(last_dim)\n",
    "        self.h1 = make_head(last_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.repr_net(x)\n",
    "        y0 = self.h0(z).squeeze(-1)\n",
    "        y1 = self.h1(z).squeeze(-1)\n",
    "        return y0, y1\n",
    "\n",
    "class TARNetTrainer:\n",
    "    def __init__(self, input_dim, rep_dims, head_dims, dropout):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = TARNetModel(input_dim, rep_dims, head_dims, dropout).to(self.device)\n",
    "\n",
    "    def fit(self, X_train, t_train, y_train,\n",
    "            X_val, t_val, y_val,\n",
    "            lr, weight_decay, batch_size, epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        train_ds = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(X_train, dtype=torch.float32, device=self.device),\n",
    "            torch.tensor(t_train, dtype=torch.long, device=self.device),\n",
    "            torch.tensor(y_train, dtype=torch.float32, device=self.device),\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        best_val = float(\"inf\")\n",
    "        for _ in range(epochs):\n",
    "            # training loop\n",
    "            self.model.train()\n",
    "            for xb, tb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                y0, y1 = self.model(xb)\n",
    "                y_pred = torch.where(tb == 1, y1, y0)\n",
    "                loss = criterion(y_pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # validation\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                Xv = torch.tensor(X_val, dtype=torch.float32, device=self.device)\n",
    "                tv = torch.tensor(t_val, dtype=torch.long, device=self.device)\n",
    "                yv = torch.tensor(y_val, dtype=torch.float32, device=self.device)\n",
    "                y0v, y1v = self.model(Xv)\n",
    "                ypv = torch.where(tv == 1, y1v, y0v)\n",
    "                val_loss = criterion(ypv, yv).item()\n",
    "                best_val = min(best_val, val_loss)\n",
    "\n",
    "        return best_val\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        Xb = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            y0, y1 = self.model(Xb)\n",
    "        return y0.cpu().numpy(), y1.cpu().numpy()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2) CEVAE Trainer (Pyro) with normal outcome(self, X):\n",
    "        self.wrapper.model.eval()\n",
    "        Xb = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            outs = self.wrapper.model(Xb)\n",
    "            if len(outs) == 3:\n",
    "                y0, y1, _ = outs\n",
    "            else:\n",
    "                y0, y1 = outs\n",
    "        return y0.cpu().numpy(), y1.cpu().numpy()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2) CEVAE Trainer (Pyro) with normal outcome\n",
    "# ------------------------------------------------------------------------\n",
    "class CEVAETrainer:\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim, num_layers, num_samples):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = CEVAE(\n",
    "            feature_dim=input_dim,\n",
    "            latent_dim=latent_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            num_samples=num_samples,\n",
    "            outcome_dist=\"normal\"\n",
    "        ).to(self.device)\n",
    "\n",
    "    def fit(self, X_train, t_train, y_train,\n",
    "            X_val, t_val, y_val,\n",
    "            lr, weight_decay, batch_size, epochs):\n",
    "        Xb = torch.tensor(X_train, dtype=torch.float32, device=self.device)\n",
    "        tb = torch.tensor(t_train, dtype=torch.float32, device=self.device)\n",
    "        yb = torch.tensor(y_train, dtype=torch.float32, device=self.device)\n",
    "        elbo_list = self.model.fit(\n",
    "            Xb, tb, yb,\n",
    "            num_epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "        return elbo_list[-1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xb = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        ite_samples = self.model.ite(Xb).cpu().numpy()\n",
    "        return ite_samples.mean(0)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3) DragonNet Trainer\n",
    "# ------------------------------------------------------------------------\n",
    "class DragonNetTrainer:\n",
    "    def __init__(self, input_dim, shared_hidden, outcome_hidden):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.wrapper = DragonNet(input_dim, shared_hidden, outcome_hidden)\n",
    "        # Move internal nn.Module to device\n",
    "        self.wrapper.model.to(self.device)\n",
    "\n",
    "    def fit(self, X_train, t_train, y_train,\n",
    "            X_val, t_val, y_val,\n",
    "            lr, weight_decay, batch_size, epochs):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.wrapper.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        train_ds = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(X_train, dtype=torch.float32, device=self.device),\n",
    "            torch.tensor(t_train, dtype=torch.float32, device=self.device),\n",
    "            torch.tensor(y_train, dtype=torch.float32, device=self.device)\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        best_val = float(\"inf\")\n",
    "        for _ in range(epochs):\n",
    "            # Training\n",
    "            self.wrapper.model.train()\n",
    "            for xb, tb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outs = self.wrapper.model(xb)\n",
    "                # Always take first two outputs as y0, y1\n",
    "                y0, y1 = outs[0], outs[1]\n",
    "                y_pred = torch.where(tb.unsqueeze(1) == 1, y1, y0).squeeze(-1)\n",
    "                loss = criterion(y_pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            self.wrapper.model.eval()\n",
    "            with torch.no_grad():\n",
    "                Xv = torch.tensor(X_val, dtype=torch.float32, device=self.device)\n",
    "                tv = torch.tensor(t_val, dtype=torch.float32, device=self.device)\n",
    "                yv = torch.tensor(y_val, dtype=torch.float32, device=self.device)\n",
    "                outs_v = self.wrapper.model(Xv)\n",
    "                y0v, y1v = outs_v[0], outs_v[1]\n",
    "                ypv = torch.where(tv.unsqueeze(1) == 1, y1v, y0v).squeeze(-1)\n",
    "                val_loss = criterion(ypv, yv).item()\n",
    "                best_val = min(best_val, val_loss)\n",
    "        return best_val\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.wrapper.model.eval()\n",
    "        Xb = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            outs = self.wrapper.model(Xb)\n",
    "            y0, y1 = outs[0], outs[1]\n",
    "        return y0.cpu().numpy(), y1.cpu().numpy()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4) Synthetic data & split\n",
    "# ------------------------------------------------------------------------\n",
    "def make_synthetic_data(N=1000, D=5, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    X = torch.randn(N, D)\n",
    "    w_p, b_p = torch.randn(D), 0.1\n",
    "    p = torch.sigmoid(X @ w_p + b_p)\n",
    "    t = torch.bernoulli(p)\n",
    "    beta0 = torch.randn(D)\n",
    "    y0 = X @ beta0 + 0.1 * torch.randn(N)\n",
    "    tau = (X[:, 0] * 2.0).clamp(min=0)\n",
    "    y1 = y0 + tau + 0.1 * torch.randn(N)\n",
    "    y = y0 * (1 - t) + y1 * t\n",
    "    return X.numpy(), t.numpy(), y.numpy(), y0.numpy(), y1.numpy()\n",
    "\n",
    "X, t, y, y0, y1 = make_synthetic_data(N=400, D=2)\n",
    "X_train, X_tmp, t_train, t_tmp, y_train, y_tmp = train_test_split(\n",
    "    X, t, y, test_size=0.4, random_state=42\n",
    ")\n",
    "X_val, X_test, t_val, t_test, y_val, y_test = train_test_split(\n",
    "    X_tmp, t_tmp, y_tmp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5) Optuna tuning & evaluation\n",
    "# ------------------------------------------------------------------------\n",
    "def tune_and_eval(model_name):\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "        wd = trial.suggest_loguniform(\"wd\", 1e-6, 1e-3)\n",
    "        bs = trial.suggest_categorical(\"bs\", [64, 128, 256])\n",
    "        epochs = trial.suggest_int(\"epochs\", 20, 60)\n",
    "\n",
    "        if model_name == \"tarnet\":\n",
    "            rep1 = trial.suggest_categorical(\"rep1\", [100, 200])\n",
    "            rep2 = trial.suggest_categorical(\"rep2\", [100, 200])\n",
    "            head = trial.suggest_int(\"head\", 50, 150, step=50)\n",
    "            drop = trial.suggest_uniform(\"drop\", 0.0, 0.5)\n",
    "            trainer = TARNetTrainer(\n",
    "                input_dim=X_train.shape[1], rep_dims=[rep1, rep2], head_dims=[head], dropout=drop\n",
    "            )\n",
    "        elif model_name == \"cevae\":\n",
    "            ld = trial.suggest_int(\"latent_dim\", 10, 100)\n",
    "            hd = trial.suggest_int(\"hidden_dim\", 50, 200)\n",
    "            nl = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "            ns = trial.suggest_categorical(\"num_samples\", [10, 50, 100])\n",
    "            trainer = CEVAETrainer(\n",
    "                input_dim=X_train.shape[1], latent_dim=ld,\n",
    "                hidden_dim=hd, num_layers=nl, num_samples=ns\n",
    "            )\n",
    "        else:  # dragonnet\n",
    "            sh = trial.suggest_int(\"shared_hidden\", 50, 200)\n",
    "            oh = trial.suggest_int(\"outcome_hidden\", 50, 200)\n",
    "            trainer = DragonNetTrainer(\n",
    "                input_dim=X_train.shape[1], shared_hidden=sh, outcome_hidden=oh\n",
    "            )\n",
    "\n",
    "        return trainer.fit(\n",
    "            X_train, t_train, y_train,\n",
    "            X_val, t_val, y_val,\n",
    "            lr=lr, weight_decay=wd, batch_size=bs, epochs=epochs\n",
    "        )\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=f\"{model_name}_tune\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "    best = study.best_params\n",
    "    print(f\"Best params for {model_name}: {best}\")\n",
    "\n",
    "    # retrain on train+val\n",
    "    X_trn = np.vstack([X_train, X_val])\n",
    "    t_trn = np.concatenate([t_train, t_val])\n",
    "    y_trn = np.concatenate([y_train, y_val])\n",
    "\n",
    "    if model_name == \"tarnet\":\n",
    "        trainer = TARNetTrainer(\n",
    "            input_dim=X_trn.shape[1], rep_dims=[best[\"rep1\"], best[\"rep2\"]],\n",
    "            head_dims=[best[\"head\"]], dropout=best[\"drop\"]\n",
    "        )\n",
    "    elif model_name == \"cevae\":\n",
    "        trainer = CEVAETrainer(\n",
    "            input_dim=X_trn.shape[1], latent_dim=best[\"latent_dim\"], hidden_dim=best[\"hidden_dim\"],\n",
    "            num_layers=best[\"num_layers\"], num_samples=best[\"num_samples\"]\n",
    "        )\n",
    "    else:\n",
    "        trainer = DragonNetTrainer(\n",
    "            input_dim=X_trn.shape[1], shared_hidden=best[\"shared_hidden\"], outcome_hidden=best[\"outcome_hidden\"]\n",
    "        )\n",
    "\n",
    "    trainer.fit(\n",
    "        X_trn, t_trn, y_trn,\n",
    "        X_test, t_test, y_test,\n",
    "        lr=best[\"lr\"], weight_decay=best[\"wd\"], batch_size=best[\"bs\"], epochs=best[\"epochs\"]\n",
    "    )\n",
    "\n",
    "    if model_name == \"cevae\":\n",
    "        return trainer.predict(X_test)\n",
    "    else:\n",
    "        y0p, y1p = trainer.predict(X_test)\n",
    "        return y1p - y0p\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6) Run all\n",
    "# ------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Tuning and training TARNet...\")\n",
    "    ite_tarnet = tune_and_eval(\"tarnet\")\n",
    "    print(\"TARNet ITE shape:\", ite_tarnet.shape)\n",
    "\n",
    "    print(\"Tuning and training CEVAE...\")\n",
    "    ite_cevae = tune_and_eval(\"cevae\")\n",
    "    print(\"CEVAE ITE shape:\", ite_cevae.shape)\n",
    "\n",
    "    print(\"Tuning and training DragonNet...\")\n",
    "    ite_dragonnet = tune_and_eval(\"dragonnet\")\n",
    "    print(\"DragonNet ITE shape:\", ite_dragonnet.shape)\n",
    "\n",
    "    print(\"All models complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ef7dae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98210394"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite_dragonnet.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d38eb7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05340328"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite_cevae.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3f044e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251715"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ite_tarnet.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa608ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
